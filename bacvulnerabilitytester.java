package com.seleniumwonderworks;

import org.openqa.selenium.*;
import org.openqa.selenium.chrome.*;
import io.github.bonigarcia.wdm.WebDriverManager;
import java.io.IOException;
import java.util.HashSet;

//import classes available in jsoup  
import org.jsoup.Jsoup;   
import org.jsoup.nodes.Document;   
import org.jsoup.nodes.Element;   
import org.jsoup.select.Elements;   
import java.util.*;



public class bacvulnerabilitytester {




public class Accessweb {
    HashSet<String> vulnList = new HashSet<String>();
    HashSet<String> secuList = new HashSet<String>();

    public String accessbrowser(String websiteurl) {
       
        WebDriverManager.chromedriver().setup();
        WebDriver driver = new ChromeDriver();    
        driver.get(websiteurl + "/admin"); //Checks webpage for admin login

    
        try {
            boolean username=driver.findElement(By.id("user_login")).isDisplayed();
            if(username == true)  
                System.out.println("Website has a BAC Vulnerability");
                vulnList.add(websiteurl);
                
        } catch( Exception e) {
            System.out.println("This webpage isnt BAC vulnerable");
            secuList.add(websiteurl);

        }
    
        driver.close();
        return "Complete";   
    }        
}

public class mywebcrawler {


    public HashSet<String> URLS = new HashSet<String>();
    private static final int MAX_DEPTH = 10; 
    public void collectLinks(String URL, int depth) {
    
    
        if((!URLS.contains(URL) && (depth < MAX_DEPTH))) {
            System.out.println("Level: " + depth + "[" + URL + "]");
    
            try {
                URLS.add(URL); 
    
                Document website =  Jsoup.connect(URL).get(); // Gathers html data for discovered link and puts into website variable
                Elements links = website.select("a[href]"); //returns list of links on html page
                depth ++; //increases depth 
            
                for ( Element page : links) { //loops on every link gathered from page
                    collectLinks(page.attr("abs:href"), depth); // enacts method on links, the abs: prefix makes attr actual url string
            }    
        }
            catch(IOException e) {
                System.err.println(URL + " encountered " + e.getMessage() + " Error ");
        }
    }
    
    }
}
     
public static void main(String[] args) {
  
    mywebcrawler peter = new bacvulnerabilitytester(). new mywebcrawler();
    Accessweb tester = new bacvulnerabilitytester().new Accessweb();

    peter.collectLinks("websiteurlenterhere", 0); //Make start depth 0


    HashSet<String> dump = peter.URLS;  //Gets urls from web crawler
    for ( String URL : dump){ //iterate over every url in page
        tester.accessbrowser(URL);

}
    System.out.println("List of Vulnerable Pages");
    System.out.println(Arrays.toString(tester.vulnList.toArray()));
    System.out.println("List of Non-BAC Vulnerable Pages");
    System.out.println(Arrays.toString(tester.secuList.toArray()));
}
}